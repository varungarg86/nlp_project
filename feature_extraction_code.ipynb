{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "anh0SS7zZuMt"
   },
   "source": [
    "#Demonstration: BoW, TF-IDF and Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCrWxelCcaFw"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BsetAJ5faE47",
    "outputId": "6e19216e-2da5-4092-f5ff-62ad7366dc9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Dataset:\n",
      "                                            Sentence\n",
      "0       The quick brown fox jumps over the lazy dog.\n",
      "1  Artificial intelligence is transforming the wo...\n",
      "2  Machine learning models require large datasets...\n",
      "3  Deep learning architectures such as CNNs and R...\n",
      "4  Natural language processing enables machines t...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"nlp_dataset.csv\")\n",
    "print(\"Original Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMBX9r5QaHLA"
   },
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ESrGbdnUaJfl",
    "outputId": "cd3ac60b-4a0e-49ab-8285-a4d0ccb91439"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Using NLTK\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "from nltk import pos_tag, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PMenUmQceV5"
   },
   "source": [
    "##Using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qIahvcdMa_90",
    "outputId": "9d0510c1-364f-4d23-977d-4c963069020e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Using NLTK:\n",
      "                                            Sentence  \\\n",
      "0       The quick brown fox jumps over the lazy dog.   \n",
      "1  Artificial intelligence is transforming the wo...   \n",
      "2  Machine learning models require large datasets...   \n",
      "3  Deep learning architectures such as CNNs and R...   \n",
      "4  Natural language processing enables machines t...   \n",
      "\n",
      "                                            POS_NLTK  \n",
      "0  [(The, DET), (quick, ADJ), (brown, NOUN), (fox...  \n",
      "1  [(Artificial, ADJ), (intelligence, NOUN), (is,...  \n",
      "2  [(Machine, NOUN), (learning, NOUN), (models, N...  \n",
      "3  [(Deep, NOUN), (learning, VERB), (architecture...  \n",
      "4  [(Natural, ADJ), (language, NOUN), (processing...  \n"
     ]
    }
   ],
   "source": [
    "def pos_tag_nltk(text):\n",
    "    words = word_tokenize(text)\n",
    "    return pos_tag(words, tagset='universal')\n",
    "\n",
    "df[\"POS_NLTK\"] = df[\"Sentence\"].apply(pos_tag_nltk)\n",
    "print(\"- Using NLTK:\")\n",
    "print(df[[\"Sentence\", \"POS_NLTK\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zsbNHDVRciUq"
   },
   "source": [
    "## Using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AoJ72s0VaLCr",
    "outputId": "88d2ec92-d3db-4e50-a989-372358e94043"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Using spaCy:\n",
      "                                            Sentence  \\\n",
      "0       The quick brown fox jumps over the lazy dog.   \n",
      "1  Artificial intelligence is transforming the wo...   \n",
      "2  Machine learning models require large datasets...   \n",
      "3  Deep learning architectures such as CNNs and R...   \n",
      "4  Natural language processing enables machines t...   \n",
      "\n",
      "                                           POS_spaCy  \n",
      "0  [(The, DET), (quick, ADJ), (brown, ADJ), (fox,...  \n",
      "1  [(Artificial, ADJ), (intelligence, NOUN), (is,...  \n",
      "2  [(Machine, NOUN), (learning, NOUN), (models, N...  \n",
      "3  [(Deep, PROPN), (learning, NOUN), (architectur...  \n",
      "4  [(Natural, ADJ), (language, NOUN), (processing...  \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def pos_tag_spacy(text):\n",
    "    doc = nlp(text)\n",
    "    return [(token.text, token.pos_) for token in doc]\n",
    "\n",
    "df[\"POS_spaCy\"] = df[\"Sentence\"].apply(pos_tag_spacy)\n",
    "print(\"- Using spaCy:\")\n",
    "print(df[[\"Sentence\", \"POS_spaCy\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wO66uxCLbLbn"
   },
   "source": [
    "# Bag of Words (BoW) and TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "oEc4UuDOaQ1i"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vectorizer_bow = CountVectorizer()\n",
    "vectorizer_tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVc-YWSkaShf",
    "outputId": "ac7bd686-5bad-4c92-86b1-0813a28d0e30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BoW Representation:\n",
      "   action  and  architectures  are  artificial  as  brown  buy  by  cars  ...  \\\n",
      "0       0    0              0    0           0   0      1    0   0     0  ...   \n",
      "1       0    0              0    0           1   0      0    0   0     0  ...   \n",
      "2       0    0              0    0           0   0      0    0   0     0  ...   \n",
      "3       0    1              1    1           0   1      0    0   0     0  ...   \n",
      "4       0    0              0    0           0   0      0    0   0     0  ...   \n",
      "\n",
      "   that  the  to  training  transforming  understand  urgent  use  went  world  \n",
      "0     0    2   0         0             0           0       0    0     0      0  \n",
      "1     0    1   0         0             1           0       0    0     0      1  \n",
      "2     0    0   0         1             0           0       0    0     0      0  \n",
      "3     0    0   0         0             0           0       0    0     0      0  \n",
      "4     0    0   1         0             0           1       0    0     0      0  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "# BoW Representation\n",
    "df_bow = pd.DataFrame(vectorizer_bow.fit_transform(df[\"Sentence\"]).toarray(),\n",
    "                       columns=vectorizer_bow.get_feature_names_out())\n",
    "print(\"- BoW Representation:\")\n",
    "print(df_bow.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tofqOxT-aTtR",
    "outputId": "6e260417-a7a3-43c1-faf7-9fab67c89a0b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- TF-IDF Representation:\n",
      "   action     and  architectures       are  artificial        as     brown  \\\n",
      "0     0.0  0.0000       0.000000  0.000000    0.000000  0.000000  0.344817   \n",
      "1     0.0  0.0000       0.000000  0.000000    0.443885  0.000000  0.000000   \n",
      "2     0.0  0.0000       0.000000  0.000000    0.000000  0.000000  0.000000   \n",
      "3     0.0  0.2503       0.336547  0.336547    0.000000  0.336547  0.000000   \n",
      "4     0.0  0.0000       0.000000  0.000000    0.000000  0.000000  0.000000   \n",
      "\n",
      "   buy   by  cars  ...  that       the        to  training  transforming  \\\n",
      "0  0.0  0.0   0.0  ...   0.0  0.409520  0.000000  0.000000      0.000000   \n",
      "1  0.0  0.0   0.0  ...   0.0  0.263588  0.000000  0.000000      0.443885   \n",
      "2  0.0  0.0   0.0  ...   0.0  0.000000  0.000000  0.370732      0.000000   \n",
      "3  0.0  0.0   0.0  ...   0.0  0.000000  0.000000  0.000000      0.000000   \n",
      "4  0.0  0.0   0.0  ...   0.0  0.000000  0.305902  0.000000      0.000000   \n",
      "\n",
      "   understand  urgent  use  went     world  \n",
      "0    0.000000     0.0  0.0   0.0  0.000000  \n",
      "1    0.000000     0.0  0.0   0.0  0.443885  \n",
      "2    0.000000     0.0  0.0   0.0  0.000000  \n",
      "3    0.000000     0.0  0.0   0.0  0.000000  \n",
      "4    0.359846     0.0  0.0   0.0  0.000000  \n",
      "\n",
      "[5 rows x 71 columns]\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF Representation\n",
    "df_tfidf = pd.DataFrame(vectorizer_tfidf.fit_transform(df[\"Sentence\"]).toarray(),\n",
    "                         columns=vectorizer_tfidf.get_feature_names_out())\n",
    "print(\"- TF-IDF Representation:\")\n",
    "print(df_tfidf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AsPlaC-aajU9"
   },
   "source": [
    "# Word Embeddings (Word2Vec, FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (4.4.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gensim) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gensim) (1.16.1)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from gensim) (7.5.0)\n",
      "Requirement already satisfied: wrapt in /Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages (from smart_open>=1.8.1->gensim) (1.17.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbgfzV4_aary",
    "outputId": "65cd0254-19e8-464b-9d74-b7b816d82317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Embeddings:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/varuniexpress/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nWord Embeddings:\")\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, FastText\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "sentences = [word_tokenize(sentence) for sentence in df[\"Sentence\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzymX878cm1U"
   },
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mR44_vdab91",
    "outputId": "c8c4f1b9-0635-40b8-f251-adb43be472a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Word2Vec Example (vector for 'learning'):\n",
      "[-0.00714262  0.00123934 -0.00719911 -0.00224833  0.0037139   0.00582085\n",
      "  0.00121568  0.00212919 -0.00413245  0.00721701 -0.00629886  0.0046435\n",
      " -0.00823621  0.00202604 -0.0049813  -0.00426119 -0.0030935   0.00564472\n",
      "  0.00579024 -0.0049958   0.00077382 -0.00849237  0.00781627  0.00925238\n",
      " -0.00273513  0.00078918  0.00074849  0.0054746  -0.00861361  0.00058809\n",
      "  0.00687229  0.00222359  0.00113784 -0.0093557   0.00848499 -0.00625204\n",
      " -0.00298735  0.00348573 -0.00076114  0.00139133  0.00178694 -0.00684534\n",
      " -0.00972519  0.00905068  0.00621701 -0.00690978  0.00338968  0.0002201\n",
      "  0.00475308 -0.00712166  0.00403597  0.00433994  0.00995938 -0.00447299\n",
      " -0.00139421 -0.00732321 -0.00968426 -0.00909021 -0.00103136 -0.00650065\n",
      "  0.0048594  -0.0061687   0.00253097  0.00073111 -0.00339446 -0.00096088\n",
      "  0.0099858   0.00917453 -0.00449193  0.00908251 -0.00565186  0.00594476\n",
      " -0.00308296  0.00343732  0.00304221  0.00689994 -0.00238398  0.00877762\n",
      "  0.00757861 -0.00955854 -0.00800956 -0.00763604  0.00290409 -0.00279275\n",
      " -0.00693791 -0.00813733  0.00832053  0.00198066 -0.00932058 -0.00477409\n",
      "  0.00315269 -0.00469929  0.00528944 -0.00422539  0.00267789 -0.0080412\n",
      "  0.00620596  0.00481599  0.00079116  0.0030026 ]\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "print(\"- Word2Vec Example (vector for 'learning'):\")\n",
    "print(word2vec_model.wv['learning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_czgg2ErcpYG"
   },
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Wlbs31TadPz",
    "outputId": "02b400fb-0d63-4f19-9171-5ebbd3af9908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- FastText Example (vector for 'learning'):\n",
      "[ 8.41071014e-04 -1.44253936e-05 -1.40550779e-03 -1.95405955e-05\n",
      " -1.49504491e-03 -1.56484530e-05 -7.58774171e-04 -9.25881439e-04\n",
      "  1.37625961e-03  7.78312678e-04 -4.12646274e-04  5.67153620e-04\n",
      " -1.24123076e-03  1.12083333e-03  4.30703018e-04 -1.62910367e-03\n",
      " -1.81642117e-03 -1.38210831e-03  5.55048347e-04 -2.03332305e-03\n",
      " -1.89027167e-03 -2.52464460e-03  1.56069861e-03  1.87282465e-04\n",
      " -9.09589464e-04 -8.62546614e-04  2.41440794e-04 -9.19878366e-04\n",
      " -5.59224281e-04 -1.27525767e-03 -1.46470428e-03  1.73418969e-03\n",
      "  6.40327053e-04 -2.77742220e-04  4.63260541e-04  8.35091574e-04\n",
      " -5.92246652e-04  5.62027795e-04 -1.42553693e-03 -1.01097615e-03\n",
      " -1.19380211e-03 -1.53008569e-03 -1.01618865e-03  1.19788852e-03\n",
      " -8.55557097e-04 -4.37811468e-05  1.49167347e-04  2.23333671e-04\n",
      "  2.30090140e-04  1.78240545e-04  1.63390697e-03 -6.22406893e-04\n",
      "  2.85973547e-05  1.47500460e-03  8.02899071e-04  8.26830394e-04\n",
      " -4.73300810e-04  4.35493675e-05 -2.82393332e-04 -1.19902357e-03\n",
      "  6.03922876e-04 -1.20870781e-03 -1.81641581e-03  1.53815688e-03\n",
      " -1.45952252e-03 -8.89655726e-04  1.86830934e-03  1.02528499e-03\n",
      " -5.35106170e-04 -1.01780846e-04  9.41175851e-04  3.86331667e-04\n",
      " -1.03236095e-03 -9.19252343e-04 -2.65513954e-04 -2.06728117e-04\n",
      "  1.47448201e-03  1.90274580e-03 -1.12999766e-03  7.95504311e-04\n",
      "  1.72680384e-03  1.27080875e-03 -1.37939979e-03 -1.77698341e-04\n",
      " -1.27108244e-03  5.58344414e-04  1.58333161e-03 -3.69884336e-04\n",
      " -8.75343336e-04  3.76934622e-04  1.40847359e-03  5.93925108e-07\n",
      "  4.81997238e-04  1.51696368e-04  1.12669170e-03  9.77281248e-04\n",
      " -1.68280840e-05  1.86730118e-03 -9.06115747e-04 -9.60378617e-04]\n"
     ]
    }
   ],
   "source": [
    "fasttext_model = FastText(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "print(\"- FastText Example (vector for 'learning'):\")\n",
    "print(fasttext_model.wv['learning'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2-yyTHCagnY"
   },
   "source": [
    "# Transformers (BERT-Based Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "xKgKDI-ycTSC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NJ19AydgTqfs",
    "outputId": "66b2a5fd-7959-4ec0-c55e-1018ec2630e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- BERT Embeddings Example:\n",
      "                                            Sentence  \\\n",
      "0       The quick brown fox jumps over the lazy dog.   \n",
      "1  Artificial intelligence is transforming the wo...   \n",
      "2  Machine learning models require large datasets...   \n",
      "3  Deep learning architectures such as CNNs and R...   \n",
      "4  Natural language processing enables machines t...   \n",
      "\n",
      "                                     BERT_Embeddings  \n",
      "0  [-0.01446607243269682, -0.07488731294870377, 0...  \n",
      "1  [0.21177445352077484, -0.053160350769758224, -...  \n",
      "2  [0.0969255343079567, -0.007682323455810547, -0...  \n",
      "3  [-0.19142761826515198, -0.26351794600486755, 0...  \n",
      "4  [-0.07791925966739655, 0.14749549329280853, -0...  \n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "def get_bert_embedding(text):\n",
    "    tokens = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        output = model(**tokens)\n",
    "    return output.last_hidden_state.mean(dim=1).squeeze().tolist()\n",
    "\n",
    "df[\"BERT_Embeddings\"] = df[\"Sentence\"].apply(get_bert_embedding)\n",
    "print(\"- BERT Embeddings Example:\")\n",
    "print(df[[\"Sentence\", \"BERT_Embeddings\"]].head())\n",
    "\n",
    "print(\"Processing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
